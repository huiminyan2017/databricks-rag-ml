{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a34c4ce0-027a-4417-a81a-a8197f8020f2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "What chunking does:\n",
    "\n",
    "LLMs and embedding models cannot work on full documents reliably.\n",
    "Chunking splits long documents into overlapping, semantically meaningful pieces so that:\n",
    "\n",
    "\t• embeddings capture local meaning\n",
    "\t• retrieval finds the right part of a document\n",
    "\t• generation avoids hallucination\n",
    "\n",
    "Bad chunking = bad RAG. This step is critical."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2baeca4d-6036-4eb1-a042-b872384fe459",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### 02 – Chunk Azure Compute Docs for RAG\n",
    "\n",
    "This notebook reads raw Azure Compute documentation from Unity Catalog,\n",
    "splits documents into overlapping text chunks, and writes the results\n",
    "as a new Delta table for downstream embedding and retrieval.\n",
    "\n",
    "Input table:\n",
    "- databricks_rag_demo.default.raw_azure_compute_docs\n",
    "\n",
    "Output table:\n",
    "- databricks_rag_demo.default.azure_compute_doc_chunks\n",
    "\n",
    "Chunking design:\n",
    "\n",
    "We will use:\n",
    "\n",
    "\t•\tChunk size: ~400 tokens (approx, word-based)\n",
    "\t•\tOverlap: ~50 tokens\n",
    "\t•\tDeterministic chunk IDs\n",
    "\t•\tMetadata preserved (doc_id, category, title, url)\n",
    "\n",
    "This is industry-standard for RAG."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e8d75f78-3d04-43c6-84ab-4570f8b38e8a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import ArrayType, StructType, StructField, IntegerType, StringType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "91f1afef-d5f8-4d31-aeee-ef71483f3709",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------------------------------------------+--------------------------+----------------------------------------------+\n|doc_id                                                                      |category                  |title                                         |\n+----------------------------------------------------------------------------+--------------------------+----------------------------------------------+\n|virtual-machine-scale-sets/standby-pools-create.md                          |virtual-machine-scale-sets|standby-pools-create                          |\n|virtual-machine-scale-sets/standby-pools-update-delete.md                   |virtual-machine-scale-sets|standby-pools-update-delete                   |\n|virtual-machine-scale-sets/azure-hybrid-benefit-linux.md                    |virtual-machine-scale-sets|azure-hybrid-benefit-linux                    |\n|virtual-machine-scale-sets/flexible-virtual-machine-scale-sets-powershell.md|virtual-machine-scale-sets|flexible-virtual-machine-scale-sets-powershell|\n|virtual-machine-scale-sets/virtual-machine-scale-sets-attached-disks.md     |virtual-machine-scale-sets|virtual-machine-scale-sets-attached-disks     |\n+----------------------------------------------------------------------------+--------------------------+----------------------------------------------+\n\n"
     ]
    }
   ],
   "source": [
    "# Load raw docs from Unity Catalog\n",
    "raw_df = spark.table(\n",
    "    \"databricks_rag_demo.default.raw_azure_compute_docs\"\n",
    ")\n",
    "\n",
    "raw_df.select(\"doc_id\", \"category\", \"title\").limit(5).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4c8f93c4-d72f-4680-bfea-48648239f751",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# We’ll approximate tokens by words.\n",
    "def tokenize(text: str):\n",
    "    return re.findall(r\"\\b\\w+\\b\", text.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5ab5719a-9c6e-44a0-a579-374ccb1379ba",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Chunking function (with overlap)\n",
    "def chunk_text(text, chunk_size=400, overlap=50):\n",
    "    tokens = tokenize(text)\n",
    "    chunks = []\n",
    "\n",
    "    start = 0\n",
    "    chunk_index = 0\n",
    "\n",
    "    while start < len(tokens):\n",
    "        end = start + chunk_size\n",
    "        chunk_tokens = tokens[start:end]\n",
    "        chunk_str = \" \".join(chunk_tokens)\n",
    "\n",
    "        chunks.append({\n",
    "            \"chunk_index\": chunk_index,\n",
    "            \"chunk_text\": chunk_str\n",
    "        })\n",
    "\n",
    "        chunk_index += 1\n",
    "        start += chunk_size - overlap\n",
    "\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "71f85c53-8e7a-4de7-8139-b016f9743bf0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# UDF = User Defined Function\n",
    "# A Spark UDF is: A custom function you write (usually in Python) that Spark can apply to columns of a DataFrame, distributed across the cluster.\n",
    "\n",
    "# Register Spark UDF\n",
    "chunk_schema = ArrayType(\n",
    "    StructType([\n",
    "        StructField(\"chunk_index\", IntegerType(), False),\n",
    "        StructField(\"chunk_text\", StringType(), False)\n",
    "    ])\n",
    ")\n",
    "\n",
    "chunk_udf = F.udf(chunk_text, chunk_schema)\n",
    "\n",
    "# Apply chunking + explode\n",
    "chunked_df = (\n",
    "    raw_df\n",
    "    .withColumn(\"chunks\", chunk_udf(\"raw_text\"))\n",
    "    .withColumn(\"chunk\", F.explode(\"chunks\"))\n",
    "    .select(\n",
    "        \"doc_id\",\n",
    "        \"source\",\n",
    "        \"category\",\n",
    "        \"title\",\n",
    "        \"url\",\n",
    "        F.col(\"chunk.chunk_index\").alias(\"chunk_index\"),\n",
    "        F.col(\"chunk.chunk_text\").alias(\"chunk_text\"),\n",
    "        \"ingest_time\"\n",
    "    )\n",
    ")\n",
    "\n",
    "# Add a stable chunk ID:\n",
    "chunked_df = chunked_df.withColumn(\n",
    "    \"chunk_id\",\n",
    "    F.sha2(\n",
    "        F.concat_ws(\"::\", F.col(\"doc_id\"), F.col(\"chunk_index\")),\n",
    "        256\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "952bf8ec-c45e-47b1-9fdb-314387acbf2d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##### Step 0: Input DataFrame\n",
    "\n",
    "Before chunking, the input DataFrame raw_df has one row per document:\n",
    "\n",
    "| doc_id | category | title | raw_text              | ingest_time |\n",
    "|-------|----------|-------|-----------------------|-------------|\n",
    "| vm.md | virtual-machines | Intro | \"very long text...\"   | ...         |\n",
    "\n",
    "raw_text is one long string.\n",
    "\n",
    "##### Step 1: Apply UDF\n",
    "\n",
    ".withColumn(\"chunks\", chunk_udf(\"raw_text\"))\n",
    "\n",
    "What this does:\n",
    "\n",
    "- Applies Spark UDF chunk_udf to raw_text\n",
    "- Creates a new column called chunks\n",
    "- Keeps all existing columns\n",
    "\n",
    "| doc_id | raw_text     | chunks |\n",
    "|-------|--------------|--------|\n",
    "| vm.md | \"...long...\"  | `[ {chunk_index: 0, chunk_text: \"...\"}, {chunk_index: 1, chunk_text: \"...\"} ]` |\n",
    "\n",
    "\n",
    "Still one row per document\n",
    "\n",
    "##### Step 2: Explode\n",
    "\n",
    ".withColumn(\"chunk\", F.explode(\"chunks\"))\n",
    "\n",
    "What explode does: explode takes an array and turns each element into its own row\n",
    "\n",
    "Before explode (1 row)\n",
    "```text\n",
    "chunks = [\n",
    "  {chunk_index: 0, chunk_text: \"...\"},\n",
    "  {chunk_index: 1, chunk_text: \"...\"}\n",
    "]\n",
    "```\n",
    "\n",
    "After explode (2 rows)\n",
    "| doc_id | chunk        |\n",
    "|--------|--------------|\n",
    "| vm.md  | {0, \"...\"}   |\n",
    "| vm.md  | {1, \"...\"}   |\n",
    "\n",
    "Spark duplicates all other columns automatically.\n",
    "\n",
    "Data shape now:\n",
    "| doc_id | raw_text | chunks | chunk        |\n",
    "|--------|----------|--------|--------------|\n",
    "| vm.md  | ...      | [...]  | {0, \"...\"}   |\n",
    "| vm.md  | ...      | [...]  | {1, \"...\"}   |\n",
    "\n",
    "here is one row per chunk.\n",
    "\n",
    "##### Step 3: reorganize\n",
    "\n",
    ".select(...)\n",
    "\n",
    "what it does:\n",
    "\n",
    "- Drops columns no longer need:\n",
    "\t- raw_text\n",
    "\t- chunks\n",
    "- **Extracts fields from the chunk struct**\n",
    "- Flattens the schema\n",
    "\n",
    "##### Final result\n",
    "\n",
    "chunked_df:\n",
    "\n",
    "| doc_id | category | title | chunk_index | chunk_text          |\n",
    "|--------|----------|-------|-------------|---------------------|\n",
    "| vm.md  | vm       | Intro | 0           | \"first chunk...\"    |\n",
    "| vm.md  | vm       | Intro | 1           | \"second chunk...\"   |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a3efcd49-0787-4c20-8b81-6179971672d7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "5758"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunked_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ef9ebcde-b37c-40b2-bb7a-de582dcb6905",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>doc_id</th><th>source</th><th>category</th><th>title</th><th>url</th><th>chunk_index</th><th>chunk_text</th><th>ingest_time</th><th>chunk_id</th></tr></thead><tbody><tr><td>virtual-machine-scale-sets/standby-pools-create.md</td><td>azure-compute-docs</td><td>virtual-machine-scale-sets</td><td>standby-pools-create</td><td>https://learn.microsoft.com/en-us/azure/virtual-machine-scale-sets/standby-pools-create.md</td><td>0</td><td>title create a standby pool for virtual machine scale sets description learn how to create a standby pool to reduce scale out latency with virtual machine scale sets author mimckitt ms author mimckitt ms service azure virtual machine scale sets ms custom ignite 2024 ms topic how to ms date 5 6 2025 ms reviewer cynthn customer intent as a cloud infrastructure administrator i want to create and manage a standby pool for virtual machine scale sets so that i can reduce scale out latency and ensure high availability of resources create a standby pool important for standby pools to successfully create and manage resources it requires access to the associated resources in your subscription ensure the correct permissions are assigned to the standby pool resource provider in order for your standby pool to function properly for detailed instructions see configure role permissions for standby pools this article steps through creating a standby pool for virtual machine scale sets with flexible orchestration create a standby pool portal note setting the standby pool vm state to hibernated is not yet available in the azure portal to configure a standby pool with a hibernated vm state use an alternative sdk such as cli or powershell 1 navigate to your virtual machine scale set 2 under availability scale select standby pool 3 select manage pool 4 provide a name for your pool select a provisioning state and set the maximum and minimum ready capacity 5 select save image type content source media standby pools enable standby pool after vmss creation png alt text a screenshot showing how to enable a standby pool on an existing virtual machine scale set in the azure portal you can also configure a standby pool during virtual machine scale set creation by navigating to the management tab and checking the box to enable standby pools image type content source media standby pools enable standby pool during vmss create png alt text a screenshot showing how to enable a standby pool during the virtual machine scale set create experience in the portal cli create a standby pool and associate it with an existing scale set using az standby vm pool create powershell create a standby pool and associate it with an existing scale set using new azstandbyvmpool arm template create a standby pool and associate it with an existing scale set create a template and deploy it using az</td><td>2026-01-07T07:18:12.183441Z</td><td>eb530c82dafe9473e49352dd206a5287feb8ec035d56b0c3e80eb62b1d15e376</td></tr><tr><td>virtual-machine-scale-sets/standby-pools-create.md</td><td>azure-compute-docs</td><td>virtual-machine-scale-sets</td><td>standby-pools-create</td><td>https://learn.microsoft.com/en-us/azure/virtual-machine-scale-sets/standby-pools-create.md</td><td>1</td><td>it with an existing scale set using az standby vm pool create powershell create a standby pool and associate it with an existing scale set using new azstandbyvmpool arm template create a standby pool and associate it with an existing scale set create a template and deploy it using az deployment group create or new azresourcegroupdeployment bicep create a standby pool and associate it with an existing scale set deploy the template using az deployment group create or new azresourcegroupdeployment rest create a standby pool and associate it with an existing scale set using create or update next steps learn how to update and delete a standby pool</td><td>2026-01-07T07:18:12.183441Z</td><td>731634abb2b494dc2ed1029f4b3eefea16271b25a44eb7e8dbd758c5b1a9ff9e</td></tr><tr><td>virtual-machine-scale-sets/standby-pools-update-delete.md</td><td>azure-compute-docs</td><td>virtual-machine-scale-sets</td><td>standby-pools-update-delete</td><td>https://learn.microsoft.com/en-us/azure/virtual-machine-scale-sets/standby-pools-update-delete.md</td><td>0</td><td>title delete or update a standby pool for virtual machine scale sets description learn how to delete or update a standby pool for virtual machine scale sets author mimckitt ms author mimckitt ms service azure virtual machine scale sets ms custom ignite 2024 ms topic how to ms date 5 6 2025 ms reviewer cynthn customer intent as a cloud administrator i want to update or delete standby pools in virtual machine scale sets so that i can manage resource allocation and optimize performance based on operational requirements update or delete a standby pool important for standby pools to successfully create and manage resources it requires access to the associated resources in your subscription ensure the correct permissions are assigned to the standby pool resource provider in order for your standby pool to function properly for detailed instructions see configure role permissions for standby pools you can update the state of the instances and the max ready capacity of your standby pool at any time the standby pool name can only be set during standby pool creation if updating the provisioning state to hibernated ensure that the scale set is properly configured to use hibernated vms for more information see hibernation overview when changing the provisioning state of your standby pool transitioning between the following states below are supported transitioning between a stopped deallocated state and a hibernated state is not supported if using a stopped deallocated pool and you want to instead use a hibernated pool first transition to a running pool then update the provisioning state to hibernated initial state updated state running stopped deallocated running hibernated stopped deallocated running hibernated running hibernated stopped deallocated update a standby pool portal note setting the standby pool vm state to hibernated is not yet available in the azure portal to configure a standby pool with a hibernated vm state use an alternative sdk such as cli or powershell 1 navigate to virtual machine scale set the standby pool is associated with 2 under availability scale select standby pool 3 select manage pool 4 update the configuration and save any changes image type content source media standby pools managed standby pool after vmss create png alt text a screenshot of the networking tab in the azure portal during the virtual machine scale set creation process cli update an existing standby pool using az standby vm pool update powershell update an existing</td><td>2026-01-07T07:18:12.183971Z</td><td>b0d36c396ec479a0446845a2f8ece217e0f048a75bb38eb977213b10db21a084</td></tr><tr><td>virtual-machine-scale-sets/standby-pools-update-delete.md</td><td>azure-compute-docs</td><td>virtual-machine-scale-sets</td><td>standby-pools-update-delete</td><td>https://learn.microsoft.com/en-us/azure/virtual-machine-scale-sets/standby-pools-update-delete.md</td><td>1</td><td>image type content source media standby pools managed standby pool after vmss create png alt text a screenshot of the networking tab in the azure portal during the virtual machine scale set creation process cli update an existing standby pool using az standby vm pool update powershell update an existing standby pool using update azstandbyvmpool arm template update an existing standby pool deployment deploy the updated template using az deployment group create or new azresourcegroupdeployment bicep update an existing standby pool deployment deploy the updated template using az deployment group create or new azresourcegroupdeployment rest update an existing standby pool using create or update delete a standby pool portal 1 navigate to virtual machine scale set the standby pool is associated with 2 under availability scale select standby pool 3 select delete pool 4 select delete image type content source media standby pools delete standby pool portal png alt text a screenshot showing how to delete a standby pool in the portal cli delete an existing standby pool using az standbypool delete powershell delete an existing standby pool using remove azstandbyvmpool rest delete an existing standby pool using delete next steps review the most frequently asked questions about standby pools for virtual machine scale sets</td><td>2026-01-07T07:18:12.183971Z</td><td>51e07a453a45d39f14184f4139da8bfaaaa5c3fe4de6e36566d0dc753ea01517</td></tr><tr><td>virtual-machine-scale-sets/azure-hybrid-benefit-linux.md</td><td>azure-compute-docs</td><td>virtual-machine-scale-sets</td><td>azure-hybrid-benefit-linux</td><td>https://learn.microsoft.com/en-us/azure/virtual-machine-scale-sets/azure-hybrid-benefit-linux.md</td><td>0</td><td>title azure hybrid benefit for linux virtual machine scale sets description learn how azure hybrid benefit can apply to virtual machine scale sets and save you money on linux virtual machines in azure services virtual machine scale sets author mathapli manager rochakm ms service azure virtual machine scale sets ms subservice azure hybrid benefit ms collection linux ms topic concept article ms date 06 14 2024 ms author mathapli ms custom kr2b contr experiment devx track azurecli linux related content sfi image nochange customer intent as a cloud administrator i want to utilize azure hybrid benefit for linux virtual machine scale sets so that i can reduce costs associated with running my rhel and sles instances while leveraging existing subscriptions explore azure hybrid benefit for linux virtual machine scale sets azure hybrid benefit can reduce the cost of running your red hat enterprise linux rhel and suse linux enterprise server sles virtual machine scale sets azure hybrid benefit for linux virtual machine scale sets is generally available now it s available for all rhel and sles pay as you go images from azure marketplace when you enable azure hybrid benefit the only fee that you incur is the cost of your scale set infrastructure note this article focuses on virtual machine scale sets running in uniform orchestration mode we recommend using flexible orchestration for new workloads for more information see orchestration modes for virtual machine scale sets in azure what is azure hybrid benefit for linux virtual machine scale sets azure hybrid benefit allows you to switch your virtual machine scale sets to bring your own subscription byos billing you can use your cloud access licenses from red hat or suse for this you can also switch pay as you go instances to byos without the need to redeploy a virtual machine scale set deployed from pay as you go azure marketplace images is charged both infrastructure and software fees when azure hybrid benefit is enabled image type content source media azure hybrid benefit linux azure hybrid benefit linux cost png alt text diagram that shows the effect of azure hybrid benefit on costs for linux virtual machines which linux virtual machines can use azure hybrid benefit azure hybrid benefit can be used on all rhel and sles pay as you go images from azure marketplace azure hybrid benefit isn t yet available for rhel or sles byos images or</td><td>2026-01-07T07:18:12.184325Z</td><td>647e2624515f93a04071cc5c18946bba1268828e815694c709fc00c16e70d977</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "virtual-machine-scale-sets/standby-pools-create.md",
         "azure-compute-docs",
         "virtual-machine-scale-sets",
         "standby-pools-create",
         "https://learn.microsoft.com/en-us/azure/virtual-machine-scale-sets/standby-pools-create.md",
         0,
         "title create a standby pool for virtual machine scale sets description learn how to create a standby pool to reduce scale out latency with virtual machine scale sets author mimckitt ms author mimckitt ms service azure virtual machine scale sets ms custom ignite 2024 ms topic how to ms date 5 6 2025 ms reviewer cynthn customer intent as a cloud infrastructure administrator i want to create and manage a standby pool for virtual machine scale sets so that i can reduce scale out latency and ensure high availability of resources create a standby pool important for standby pools to successfully create and manage resources it requires access to the associated resources in your subscription ensure the correct permissions are assigned to the standby pool resource provider in order for your standby pool to function properly for detailed instructions see configure role permissions for standby pools this article steps through creating a standby pool for virtual machine scale sets with flexible orchestration create a standby pool portal note setting the standby pool vm state to hibernated is not yet available in the azure portal to configure a standby pool with a hibernated vm state use an alternative sdk such as cli or powershell 1 navigate to your virtual machine scale set 2 under availability scale select standby pool 3 select manage pool 4 provide a name for your pool select a provisioning state and set the maximum and minimum ready capacity 5 select save image type content source media standby pools enable standby pool after vmss creation png alt text a screenshot showing how to enable a standby pool on an existing virtual machine scale set in the azure portal you can also configure a standby pool during virtual machine scale set creation by navigating to the management tab and checking the box to enable standby pools image type content source media standby pools enable standby pool during vmss create png alt text a screenshot showing how to enable a standby pool during the virtual machine scale set create experience in the portal cli create a standby pool and associate it with an existing scale set using az standby vm pool create powershell create a standby pool and associate it with an existing scale set using new azstandbyvmpool arm template create a standby pool and associate it with an existing scale set create a template and deploy it using az",
         "2026-01-07T07:18:12.183441Z",
         "eb530c82dafe9473e49352dd206a5287feb8ec035d56b0c3e80eb62b1d15e376"
        ],
        [
         "virtual-machine-scale-sets/standby-pools-create.md",
         "azure-compute-docs",
         "virtual-machine-scale-sets",
         "standby-pools-create",
         "https://learn.microsoft.com/en-us/azure/virtual-machine-scale-sets/standby-pools-create.md",
         1,
         "it with an existing scale set using az standby vm pool create powershell create a standby pool and associate it with an existing scale set using new azstandbyvmpool arm template create a standby pool and associate it with an existing scale set create a template and deploy it using az deployment group create or new azresourcegroupdeployment bicep create a standby pool and associate it with an existing scale set deploy the template using az deployment group create or new azresourcegroupdeployment rest create a standby pool and associate it with an existing scale set using create or update next steps learn how to update and delete a standby pool",
         "2026-01-07T07:18:12.183441Z",
         "731634abb2b494dc2ed1029f4b3eefea16271b25a44eb7e8dbd758c5b1a9ff9e"
        ],
        [
         "virtual-machine-scale-sets/standby-pools-update-delete.md",
         "azure-compute-docs",
         "virtual-machine-scale-sets",
         "standby-pools-update-delete",
         "https://learn.microsoft.com/en-us/azure/virtual-machine-scale-sets/standby-pools-update-delete.md",
         0,
         "title delete or update a standby pool for virtual machine scale sets description learn how to delete or update a standby pool for virtual machine scale sets author mimckitt ms author mimckitt ms service azure virtual machine scale sets ms custom ignite 2024 ms topic how to ms date 5 6 2025 ms reviewer cynthn customer intent as a cloud administrator i want to update or delete standby pools in virtual machine scale sets so that i can manage resource allocation and optimize performance based on operational requirements update or delete a standby pool important for standby pools to successfully create and manage resources it requires access to the associated resources in your subscription ensure the correct permissions are assigned to the standby pool resource provider in order for your standby pool to function properly for detailed instructions see configure role permissions for standby pools you can update the state of the instances and the max ready capacity of your standby pool at any time the standby pool name can only be set during standby pool creation if updating the provisioning state to hibernated ensure that the scale set is properly configured to use hibernated vms for more information see hibernation overview when changing the provisioning state of your standby pool transitioning between the following states below are supported transitioning between a stopped deallocated state and a hibernated state is not supported if using a stopped deallocated pool and you want to instead use a hibernated pool first transition to a running pool then update the provisioning state to hibernated initial state updated state running stopped deallocated running hibernated stopped deallocated running hibernated running hibernated stopped deallocated update a standby pool portal note setting the standby pool vm state to hibernated is not yet available in the azure portal to configure a standby pool with a hibernated vm state use an alternative sdk such as cli or powershell 1 navigate to virtual machine scale set the standby pool is associated with 2 under availability scale select standby pool 3 select manage pool 4 update the configuration and save any changes image type content source media standby pools managed standby pool after vmss create png alt text a screenshot of the networking tab in the azure portal during the virtual machine scale set creation process cli update an existing standby pool using az standby vm pool update powershell update an existing",
         "2026-01-07T07:18:12.183971Z",
         "b0d36c396ec479a0446845a2f8ece217e0f048a75bb38eb977213b10db21a084"
        ],
        [
         "virtual-machine-scale-sets/standby-pools-update-delete.md",
         "azure-compute-docs",
         "virtual-machine-scale-sets",
         "standby-pools-update-delete",
         "https://learn.microsoft.com/en-us/azure/virtual-machine-scale-sets/standby-pools-update-delete.md",
         1,
         "image type content source media standby pools managed standby pool after vmss create png alt text a screenshot of the networking tab in the azure portal during the virtual machine scale set creation process cli update an existing standby pool using az standby vm pool update powershell update an existing standby pool using update azstandbyvmpool arm template update an existing standby pool deployment deploy the updated template using az deployment group create or new azresourcegroupdeployment bicep update an existing standby pool deployment deploy the updated template using az deployment group create or new azresourcegroupdeployment rest update an existing standby pool using create or update delete a standby pool portal 1 navigate to virtual machine scale set the standby pool is associated with 2 under availability scale select standby pool 3 select delete pool 4 select delete image type content source media standby pools delete standby pool portal png alt text a screenshot showing how to delete a standby pool in the portal cli delete an existing standby pool using az standbypool delete powershell delete an existing standby pool using remove azstandbyvmpool rest delete an existing standby pool using delete next steps review the most frequently asked questions about standby pools for virtual machine scale sets",
         "2026-01-07T07:18:12.183971Z",
         "51e07a453a45d39f14184f4139da8bfaaaa5c3fe4de6e36566d0dc753ea01517"
        ],
        [
         "virtual-machine-scale-sets/azure-hybrid-benefit-linux.md",
         "azure-compute-docs",
         "virtual-machine-scale-sets",
         "azure-hybrid-benefit-linux",
         "https://learn.microsoft.com/en-us/azure/virtual-machine-scale-sets/azure-hybrid-benefit-linux.md",
         0,
         "title azure hybrid benefit for linux virtual machine scale sets description learn how azure hybrid benefit can apply to virtual machine scale sets and save you money on linux virtual machines in azure services virtual machine scale sets author mathapli manager rochakm ms service azure virtual machine scale sets ms subservice azure hybrid benefit ms collection linux ms topic concept article ms date 06 14 2024 ms author mathapli ms custom kr2b contr experiment devx track azurecli linux related content sfi image nochange customer intent as a cloud administrator i want to utilize azure hybrid benefit for linux virtual machine scale sets so that i can reduce costs associated with running my rhel and sles instances while leveraging existing subscriptions explore azure hybrid benefit for linux virtual machine scale sets azure hybrid benefit can reduce the cost of running your red hat enterprise linux rhel and suse linux enterprise server sles virtual machine scale sets azure hybrid benefit for linux virtual machine scale sets is generally available now it s available for all rhel and sles pay as you go images from azure marketplace when you enable azure hybrid benefit the only fee that you incur is the cost of your scale set infrastructure note this article focuses on virtual machine scale sets running in uniform orchestration mode we recommend using flexible orchestration for new workloads for more information see orchestration modes for virtual machine scale sets in azure what is azure hybrid benefit for linux virtual machine scale sets azure hybrid benefit allows you to switch your virtual machine scale sets to bring your own subscription byos billing you can use your cloud access licenses from red hat or suse for this you can also switch pay as you go instances to byos without the need to redeploy a virtual machine scale set deployed from pay as you go azure marketplace images is charged both infrastructure and software fees when azure hybrid benefit is enabled image type content source media azure hybrid benefit linux azure hybrid benefit linux cost png alt text diagram that shows the effect of azure hybrid benefit on costs for linux virtual machines which linux virtual machines can use azure hybrid benefit azure hybrid benefit can be used on all rhel and sles pay as you go images from azure marketplace azure hybrid benefit isn t yet available for rhel or sles byos images or",
         "2026-01-07T07:18:12.184325Z",
         "647e2624515f93a04071cc5c18946bba1268828e815694c709fc00c16e70d977"
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "doc_id",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "source",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "category",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "title",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "url",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "chunk_index",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "chunk_text",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "ingest_time",
         "type": "\"timestamp\""
        },
        {
         "metadata": "{}",
         "name": "chunk_id",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(chunked_df.limit(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fc870ed9-2fec-4ad7-9fcd-4bd9499d56bc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Write chunk table to Unity Catalog\n",
    "\n",
    "(\n",
    "    chunked_df\n",
    "    .write\n",
    "    .format(\"delta\")\n",
    "    .mode(\"overwrite\")\n",
    "    .saveAsTable(\n",
    "        \"databricks_rag_demo.default.azure_compute_doc_chunks\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "712d78f9-9729-488c-ab36-f106888dea9f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>count(1)</th></tr></thead><tbody><tr><td>5758</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         5758
        ]
       ],
       "datasetInfos": [
        {
         "name": "_sqldf",
         "schema": {
          "fields": [
           {
            "metadata": {
             "__autoGeneratedAlias": "true"
            },
            "name": "count(1)",
            "nullable": false,
            "type": "long"
           }
          ],
          "type": "struct"
         },
         "tableIdentifier": null,
         "typeStr": "pyspark.sql.connect.dataframe.DataFrame"
        }
       ],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "createTempViewForImplicitDf": true,
        "dataframeName": "_sqldf",
        "executionCount": 21
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{\"__autoGeneratedAlias\":\"true\"}",
         "name": "count(1)",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "\n",
    "SELECT COUNT(*) FROM databricks_rag_demo.default.azure_compute_doc_chunks;\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "698e2069-a359-4c99-bb51-a05a922ed3d8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>category</th><th>chunks</th></tr></thead><tbody><tr><td>virtual-machines</td><td>3259</td></tr><tr><td>service-fabric</td><td>1865</td></tr><tr><td>virtual-machine-scale-sets</td><td>341</td></tr><tr><td>container-instances</td><td>268</td></tr><tr><td>azure-impact-reporting</td><td>25</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "virtual-machines",
         3259
        ],
        [
         "service-fabric",
         1865
        ],
        [
         "virtual-machine-scale-sets",
         341
        ],
        [
         "container-instances",
         268
        ],
        [
         "azure-impact-reporting",
         25
        ]
       ],
       "datasetInfos": [
        {
         "name": "_sqldf",
         "schema": {
          "fields": [
           {
            "metadata": {},
            "name": "category",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "chunks",
            "nullable": false,
            "type": "long"
           }
          ],
          "type": "struct"
         },
         "tableIdentifier": null,
         "typeStr": "pyspark.sql.connect.dataframe.DataFrame"
        }
       ],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "createTempViewForImplicitDf": true,
        "dataframeName": "_sqldf",
        "executionCount": 22
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "category",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "chunks",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "\n",
    "SELECT category, COUNT(*) AS chunks FROM databricks_rag_demo.default.azure_compute_doc_chunks GROUP BY category ORDER BY chunks DESC;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "069537b3-4e0d-499f-bffc-8f691012f9e5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>doc_id</th><th>chunk_index</th><th>chunk_len</th></tr></thead><tbody><tr><td>virtual-machines/extensions/salt-minion.md</td><td>0</td><td>2383</td></tr><tr><td>virtual-machines/extensions/salt-minion.md</td><td>1</td><td>527</td></tr><tr><td>virtual-machines/extensions/backup-azure-sql-server-running-azure-vm.md</td><td>0</td><td>3559</td></tr><tr><td>virtual-machines/extensions/backup-azure-sql-server-running-azure-vm.md</td><td>1</td><td>1269</td></tr><tr><td>virtual-machines/extensions/custom-script-linux.md</td><td>0</td><td>2322</td></tr><tr><td>virtual-machines/extensions/custom-script-linux.md</td><td>1</td><td>2072</td></tr><tr><td>virtual-machines/extensions/custom-script-linux.md</td><td>2</td><td>2647</td></tr><tr><td>virtual-machines/extensions/custom-script-linux.md</td><td>3</td><td>2407</td></tr><tr><td>virtual-machines/extensions/custom-script-linux.md</td><td>4</td><td>2300</td></tr><tr><td>virtual-machines/extensions/custom-script-linux.md</td><td>5</td><td>2471</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "virtual-machines/extensions/salt-minion.md",
         0,
         2383
        ],
        [
         "virtual-machines/extensions/salt-minion.md",
         1,
         527
        ],
        [
         "virtual-machines/extensions/backup-azure-sql-server-running-azure-vm.md",
         0,
         3559
        ],
        [
         "virtual-machines/extensions/backup-azure-sql-server-running-azure-vm.md",
         1,
         1269
        ],
        [
         "virtual-machines/extensions/custom-script-linux.md",
         0,
         2322
        ],
        [
         "virtual-machines/extensions/custom-script-linux.md",
         1,
         2072
        ],
        [
         "virtual-machines/extensions/custom-script-linux.md",
         2,
         2647
        ],
        [
         "virtual-machines/extensions/custom-script-linux.md",
         3,
         2407
        ],
        [
         "virtual-machines/extensions/custom-script-linux.md",
         4,
         2300
        ],
        [
         "virtual-machines/extensions/custom-script-linux.md",
         5,
         2471
        ]
       ],
       "datasetInfos": [
        {
         "name": "_sqldf",
         "schema": {
          "fields": [
           {
            "metadata": {},
            "name": "doc_id",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "chunk_index",
            "nullable": true,
            "type": "integer"
           },
           {
            "metadata": {},
            "name": "chunk_len",
            "nullable": true,
            "type": "integer"
           }
          ],
          "type": "struct"
         },
         "tableIdentifier": null,
         "typeStr": "pyspark.sql.connect.dataframe.DataFrame"
        }
       ],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "createTempViewForImplicitDf": true,
        "dataframeName": "_sqldf",
        "executionCount": 24
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "doc_id",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "chunk_index",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "chunk_len",
         "type": "\"integer\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "\n",
    "SELECT doc_id, chunk_index, LENGTH(chunk_text) AS chunk_len FROM databricks_rag_demo.default.azure_compute_doc_chunks LIMIT 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "02652dc1-2a7a-4bf1-8bc4-363624c2e596",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- delete this table if needed, this will clean up the environment\n",
    "\n",
    "DROP TABLE databricks_rag_demo.default.azure_compute_doc_chunks;"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 8004489376597627,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "02_chunk_azure_compute_docs",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}