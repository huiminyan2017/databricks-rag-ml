{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64b4d919",
   "metadata": {},
   "source": [
    "#### 01 - Ingest Azure Compute Documentation into databricks Unity Catalog\n",
    "\n",
    "This notebook downloads Azure Compute documentation from GitHub, cleans Markdown content, and writes the data into a Unity Catalog–managed Delta table.\n",
    "\n",
    "**Execution environment**\n",
    "- Run this notebook on **Azure Databricks (Premium tier)** with **Unity Catalog enabled**\n",
    "- Uses a **single-user Databricks cluster** (DBR 15+)\n",
    "- Writes data as **Unity Catalog–managed Delta tables**\n",
    "\n",
    "**What this notebook does**\n",
    "- Downloads the latest Azure Compute documentation from the public GitHub repository  \n",
    "  `MicrosoftDocs/azure-compute-docs` using a shallow Git clone\n",
    "- Parses and cleans Markdown files under the `articles/` directory\n",
    "- Extracts metadata such as document ID, category, title, source URL, and ingestion time\n",
    "- Persists the processed documents into a governed Delta table:\n",
    "databricks_rag_demo.default.raw_azure_compute_docs\n",
    "\n",
    "This notebook establishes the **raw document ingestion layer** for a\n",
    "Retrieval-Augmented Generation (RAG) pipeline and intentionally avoids\n",
    "legacy DBFS-based storage in favor of **Unity Catalog–managed data objects**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c358fb0f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# gitpython is a Python wrapper around the git command. We will use this to do git clone\n",
    "\n",
    "%pip install gitpython # gitpython is a Python wrapper around the git command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e95ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from git import Repo\n",
    "import os\n",
    "import re\n",
    "from pathlib import Path\n",
    "from pyspark.sql import Row\n",
    "from datetime import datetime\n",
    "from git import Repo\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f94389",
   "metadata": {},
   "outputs": [],
   "source": [
    "REPO_URL = \"https://github.com/MicrosoftDocs/azure-compute-docs.git\"\n",
    "\n",
    "TARGET_DIR = \"/tmp/azure-compute-docs\" # it will be created on the driver VM’s local disk.\n",
    "TARGET_ARTICLE_PATH = f\"{TARGET_DIR}/articles\"\n",
    "\n",
    "# workspace will create a catelog with same name as the workspace, we will mostly work in this table\n",
    "DEFAULT_CATELOG_NAME = \"databricks_rag_demo\"\n",
    "TABLE_NAME=\"raw_azure_compute_docs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c1e578",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_azure_compute_docs():\n",
    "    \n",
    "    # clean existing or any partial clones\n",
    "    if os.path.exists(TARGET_DIR):\n",
    "        shutil.rmtree(TARGET_DIR)\n",
    "\n",
    "    # SHALLOW clone\n",
    "    Repo.clone_from(\n",
    "        REPO_URL,\n",
    "        TARGET_DIR,\n",
    "        depth=1 # Depth = how much git history you download\n",
    "    )\n",
    "\n",
    "download_azure_compute_docs()\n",
    "os.listdir(f\"{BASE_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71236b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to clean markdown text\n",
    "def clean_markdown(md_text: str) -> str:\n",
    "    # Remove code blocks\n",
    "    md_text = re.sub(r\"```.*?```\", \"\", md_text, flags=re.S)\n",
    "    # Remove images\n",
    "    md_text = re.sub(r\"!\\[.*?\\]\\(.*?\\)\", \"\", md_text)\n",
    "    # Remove links but keep text\n",
    "    md_text = re.sub(r\"\\[(.*?)\\]\\(.*?\\)\", r\"\\1\", md_text)\n",
    "    # Remove headings symbols\n",
    "    md_text = re.sub(r\"#+ \", \"\", md_text)\n",
    "    return md_text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a61526f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data():\n",
    "    article_path = Path(TARGET_ARTICLE_PATH)\n",
    "    rows = []\n",
    "    min_length = 500  # skip stubs / TOCs\n",
    "\n",
    "    for md_file in article_path.rglob(\"*.md\"):\n",
    "        try:\n",
    "            with open(md_file, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
    "                raw_md = f.read()\n",
    "\n",
    "            cleaned = clean_markdown(raw_md)\n",
    "\n",
    "            if len(cleaned) < min_length:\n",
    "                continue\n",
    "\n",
    "            rows.append(Row(\n",
    "                doc_id=str(md_file.relative_to(article_path)),\n",
    "                source=\"azure-compute-docs\",\n",
    "                category=md_file.parts[0],  # e.g. virtual-machines\n",
    "                title=md_file.stem,\n",
    "                raw_text=cleaned,\n",
    "                url=f\"https://learn.microsoft.com/en-us/azure/{md_file.relative_to(TARGET_ARTICLE_PATH)}\",\n",
    "                ingest_time=datetime.utcnow()\n",
    "            ))\n",
    "\n",
    "        except Exception as e:\n",
    "            # Fail-safe: skip bad files\n",
    "            continue\n",
    "    return rows\n",
    "\n",
    "rows = prepare_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a5880ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_table(rows):\n",
    "\n",
    "    docs_df = spark.createDataFrame(rows)\n",
    "\n",
    "    # write to warehouse\n",
    "    (\n",
    "        docs_df\n",
    "        .write\n",
    "        .format(\"delta\")\n",
    "        .mode(\"overwrite\")\n",
    "        .saveAsTable(f\"{DEFAULT_CATELOG_NAME}.default.{TABLE_NAME}\")\n",
    "    )\n",
    "\n",
    "save_to_table(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b94cfebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Validate data is stored into the table successfully\n",
    "\n",
    "TODO ADD\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
