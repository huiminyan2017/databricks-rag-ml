{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8304ea6d-cea8-4b5c-a9d1-abd2c140cfb2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### 07 - Serving + Demo (Portfolio Style)\n",
    "\n",
    "This notebook packages the RAG pipeline into a single callable `ask()` function:\n",
    "1) Embed the question (Azure OpenAI)\n",
    "2) Retrieve top-k chunks (Option A brute-force or Option B Vector Search)\n",
    "3) Build a grounded prompt\n",
    "4) Generate an answer (Azure OpenAI)\n",
    "5) Log the request/response to `rag_query_logs`\n",
    "6) (Optional) Evaluate the answer and write to `rag_evaluations`\n",
    "\n",
    "Output is a JSON-like dict that can later be used for an API or a simple UI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4adf9c1c-bb61-495f-9588-be3d06d437b1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run ./00_install_deps_and_restart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "16f1444a-61df-4b43-b3f2-e8dd867f317c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run ./00_constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cdb295af-4710-40f5-915c-39e01b280845",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai<2.0.0,>=1.0.0\n  Downloading openai-1.109.1-py3-none-any.whl.metadata (29 kB)\nCollecting anyio<5,>=3.5.0 (from openai<2.0.0,>=1.0.0)\n  Downloading anyio-4.12.1-py3-none-any.whl.metadata (4.3 kB)\nRequirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai<2.0.0,>=1.0.0) (1.9.0)\nCollecting httpx<1,>=0.23.0 (from openai<2.0.0,>=1.0.0)\n  Downloading httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\nCollecting jiter<1,>=0.4.0 (from openai<2.0.0,>=1.0.0)\n  Downloading jiter-0.12.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)\nRequirement already satisfied: pydantic<3,>=1.9.0 in /databricks/python3/lib/python3.12/site-packages (from openai<2.0.0,>=1.0.0) (2.8.2)\nCollecting sniffio (from openai<2.0.0,>=1.0.0)\n  Downloading sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\nCollecting tqdm>4 (from openai<2.0.0,>=1.0.0)\n  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n\u001B[?25l     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/57.7 kB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\n\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m57.7/57.7 kB\u001B[0m \u001B[31m2.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hRequirement already satisfied: typing-extensions<5,>=4.11 in /databricks/python3/lib/python3.12/site-packages (from openai<2.0.0,>=1.0.0) (4.11.0)\nRequirement already satisfied: idna>=2.8 in /databricks/python3/lib/python3.12/site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.0.0) (3.7)\nRequirement already satisfied: certifi in /databricks/python3/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.0.0) (2024.6.2)\nCollecting httpcore==1.* (from httpx<1,>=0.23.0->openai<2.0.0,>=1.0.0)\n  Downloading httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\nCollecting h11>=0.16 (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.0.0)\n  Downloading h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\nRequirement already satisfied: annotated-types>=0.4.0 in /databricks/python3/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai<2.0.0,>=1.0.0) (0.7.0)\nRequirement already satisfied: pydantic-core==2.20.1 in /databricks/python3/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai<2.0.0,>=1.0.0) (2.20.1)\nDownloading openai-1.109.1-py3-none-any.whl (948 kB)\n\u001B[?25l   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/948.6 kB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\n\u001B[2K   \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m\u001B[90m━━━━━━━━━━━━\u001B[0m \u001B[32m655.4/948.6 kB\u001B[0m \u001B[31m20.3 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\n\u001B[2K   \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m \u001B[32m942.1/948.6 kB\u001B[0m \u001B[31m20.7 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\n\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m948.6/948.6 kB\u001B[0m \u001B[31m13.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hDownloading anyio-4.12.1-py3-none-any.whl (113 kB)\n\u001B[?25l   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/113.6 kB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\n\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m113.6/113.6 kB\u001B[0m \u001B[31m6.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hDownloading httpx-0.28.1-py3-none-any.whl (73 kB)\n\u001B[?25l   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/73.5 kB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\n\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m73.5/73.5 kB\u001B[0m \u001B[31m4.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hDownloading httpcore-1.0.9-py3-none-any.whl (78 kB)\n\u001B[?25l   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/78.8 kB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\n\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m78.8/78.8 kB\u001B[0m \u001B[31m5.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hDownloading jiter-0.12.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (361 kB)\n\u001B[?25l   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/361.3 kB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\n\u001B[2K   \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m \u001B[32m358.4/361.3 kB\u001B[0m \u001B[31m33.2 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\n\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m361.3/361.3 kB\u001B[0m \u001B[31m7.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hDownloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n\u001B[?25l   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/78.5 kB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\n\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m78.5/78.5 kB\u001B[0m \u001B[31m3.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hDownloading sniffio-1.3.1-py3-none-any.whl (10 kB)\nDownloading h11-0.16.0-py3-none-any.whl (37 kB)\nInstalling collected packages: tqdm, sniffio, jiter, h11, anyio, httpcore, httpx, openai\nSuccessfully installed anyio-4.12.1 h11-0.16.0 httpcore-1.0.9 httpx-0.28.1 jiter-0.12.0 openai-1.109.1 sniffio-1.3.1 tqdm-4.67.1\n\u001B[43mNote: you may need to restart the kernel using %restart_python or dbutils.library.restartPython() to use updated packages.\u001B[0m\nCollecting databricks-vectorsearch\n  Downloading databricks_vectorsearch-0.63-py3-none-any.whl.metadata (2.8 kB)\nCollecting deprecation>=2 (from databricks-vectorsearch)\n  Downloading deprecation-2.1.0-py2.py3-none-any.whl.metadata (4.6 kB)\nRequirement already satisfied: mlflow-skinny<4,>=2.11.3 in /databricks/python3/lib/python3.12/site-packages (from databricks-vectorsearch) (2.19.0)\nRequirement already satisfied: protobuf<7,>=3.12.0 in /databricks/python3/lib/python3.12/site-packages (from databricks-vectorsearch) (4.24.1)\nRequirement already satisfied: requests>=2 in /databricks/python3/lib/python3.12/site-packages (from databricks-vectorsearch) (2.32.2)\nRequirement already satisfied: packaging in /databricks/python3/lib/python3.12/site-packages (from deprecation>=2->databricks-vectorsearch) (24.1)\nRequirement already satisfied: cachetools<6,>=5.0.0 in /databricks/python3/lib/python3.12/site-packages (from mlflow-skinny<4,>=2.11.3->databricks-vectorsearch) (5.3.3)\nRequirement already satisfied: click<9,>=7.0 in /databricks/python3/lib/python3.12/site-packages (from mlflow-skinny<4,>=2.11.3->databricks-vectorsearch) (8.1.7)\nRequirement already satisfied: cloudpickle<4 in /databricks/python3/lib/python3.12/site-packages (from mlflow-skinny<4,>=2.11.3->databricks-vectorsearch) (2.2.1)\nRequirement already satisfied: databricks-sdk<1,>=0.20.0 in /databricks/python3/lib/python3.12/site-packages (from mlflow-skinny<4,>=2.11.3->databricks-vectorsearch) (0.30.0)\nRequirement already satisfied: gitpython<4,>=3.1.9 in /databricks/python3/lib/python3.12/site-packages (from mlflow-skinny<4,>=2.11.3->databricks-vectorsearch) (3.1.37)\nRequirement already satisfied: importlib_metadata!=4.7.0,<9,>=3.7.0 in /databricks/python3/lib/python3.12/site-packages (from mlflow-skinny<4,>=2.11.3->databricks-vectorsearch) (6.0.0)\nRequirement already satisfied: opentelemetry-api<3,>=1.9.0 in /databricks/python3/lib/python3.12/site-packages (from mlflow-skinny<4,>=2.11.3->databricks-vectorsearch) (1.27.0)\nRequirement already satisfied: opentelemetry-sdk<3,>=1.9.0 in /databricks/python3/lib/python3.12/site-packages (from mlflow-skinny<4,>=2.11.3->databricks-vectorsearch) (1.27.0)\nRequirement already satisfied: pyyaml<7,>=5.1 in /databricks/python3/lib/python3.12/site-packages (from mlflow-skinny<4,>=2.11.3->databricks-vectorsearch) (6.0.1)\nRequirement already satisfied: sqlparse<1,>=0.4.0 in /databricks/python3/lib/python3.12/site-packages (from mlflow-skinny<4,>=2.11.3->databricks-vectorsearch) (0.5.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /databricks/python3/lib/python3.12/site-packages (from requests>=2->databricks-vectorsearch) (2.0.4)\nRequirement already satisfied: idna<4,>=2.5 in /databricks/python3/lib/python3.12/site-packages (from requests>=2->databricks-vectorsearch) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /databricks/python3/lib/python3.12/site-packages (from requests>=2->databricks-vectorsearch) (1.26.16)\nRequirement already satisfied: certifi>=2017.4.17 in /databricks/python3/lib/python3.12/site-packages (from requests>=2->databricks-vectorsearch) (2024.6.2)\nRequirement already satisfied: google-auth~=2.0 in /databricks/python3/lib/python3.12/site-packages (from databricks-sdk<1,>=0.20.0->mlflow-skinny<4,>=2.11.3->databricks-vectorsearch) (2.35.0)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /databricks/python3/lib/python3.12/site-packages (from gitpython<4,>=3.1.9->mlflow-skinny<4,>=2.11.3->databricks-vectorsearch) (4.0.11)\nRequirement already satisfied: zipp>=0.5 in /databricks/python3/lib/python3.12/site-packages (from importlib_metadata!=4.7.0,<9,>=3.7.0->mlflow-skinny<4,>=2.11.3->databricks-vectorsearch) (3.17.0)\nRequirement already satisfied: deprecated>=1.2.6 in /databricks/python3/lib/python3.12/site-packages (from opentelemetry-api<3,>=1.9.0->mlflow-skinny<4,>=2.11.3->databricks-vectorsearch) (1.2.14)\nRequirement already satisfied: opentelemetry-semantic-conventions==0.48b0 in /databricks/python3/lib/python3.12/site-packages (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny<4,>=2.11.3->databricks-vectorsearch) (0.48b0)\nRequirement already satisfied: typing-extensions>=3.7.4 in /databricks/python3/lib/python3.12/site-packages (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny<4,>=2.11.3->databricks-vectorsearch) (4.11.0)\nRequirement already satisfied: wrapt<2,>=1.10 in /databricks/python3/lib/python3.12/site-packages (from deprecated>=1.2.6->opentelemetry-api<3,>=1.9.0->mlflow-skinny<4,>=2.11.3->databricks-vectorsearch) (1.14.1)\nRequirement already satisfied: smmap<6,>=3.0.1 in /databricks/python3/lib/python3.12/site-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny<4,>=2.11.3->databricks-vectorsearch) (5.0.0)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /databricks/python3/lib/python3.12/site-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny<4,>=2.11.3->databricks-vectorsearch) (0.2.8)\nRequirement already satisfied: rsa<5,>=3.1.4 in /databricks/python3/lib/python3.12/site-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny<4,>=2.11.3->databricks-vectorsearch) (4.9)\nRequirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /databricks/python3/lib/python3.12/site-packages (from pyasn1-modules>=0.2.1->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny<4,>=2.11.3->databricks-vectorsearch) (0.4.8)\nDownloading databricks_vectorsearch-0.63-py3-none-any.whl (19 kB)\nDownloading deprecation-2.1.0-py2.py3-none-any.whl (11 kB)\nInstalling collected packages: deprecation, databricks-vectorsearch\nSuccessfully installed databricks-vectorsearch-0.63 deprecation-2.1.0\n\u001B[43mNote: you may need to restart the kernel using %restart_python or dbutils.library.restartPython() to use updated packages.\u001B[0m\nNew packages installed — restarting Python kernel...\n\u001B[43mWarning: statements after `dbutils.library.restartPython()` will execute before Python is restarted.\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "%run ./00_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5ac66aac-2a2a-4c4e-b05c-e0fcaa273cfb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run ./00_init_openai_client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "acd8dce4-658d-42f8-a9d4-2c932521a7cf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from typing import List, Dict, Any\n",
    "from datetime import datetime\n",
    "\n",
    "# Helpers: validate chunk schema + compact sources\n",
    "\n",
    "def _validate_chunks(chunks: List[Dict[str, Any]]):\n",
    "    if not isinstance(chunks, list):\n",
    "        raise TypeError(\"retrieved_chunks must be a list[dict]\")\n",
    "    if len(chunks) == 0:\n",
    "        return\n",
    "    required = {\"chunk_id\", \"doc_id\", \"title\", \"url\", \"chunk_index\", \"chunk_text\", \"category\", \"score\"}\n",
    "    missing = required - set(chunks[0].keys())\n",
    "    if missing:\n",
    "        raise ValueError(f\"retrieved_chunks items missing keys: {missing}\")\n",
    "\n",
    "def _compact_sources(chunks: List[Dict[str, Any]]):\n",
    "    # Return a minimal source list for the final API-like payload\n",
    "    sources = []\n",
    "    for c in chunks:\n",
    "        sources.append({\n",
    "            \"title\": c.get(\"title\"),\n",
    "            \"url\": c.get(\"url\"),\n",
    "            \"category\": c.get(\"category\"),\n",
    "            \"chunk_id\": c.get(\"chunk_id\"),\n",
    "            \"chunk_index\": c.get(\"chunk_index\"),\n",
    "            \"score\": c.get(\"score\"),\n",
    "        })\n",
    "    return sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "91991a1a-ac73-4c28-b346-9966818b395c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# The unified pipeline function: ask():\n",
    "# embed → retrieve → prompt → Azure OpenAI → log → (optional) evaluate → return JSON. It \n",
    "# also includes a simple notebook “UI” cell and a few SQL queries to show metrics.\n",
    "\n",
    "def ask(\n",
    "    question: str,\n",
    "    *,\n",
    "    k: int = 6,\n",
    "    retriever: str = \"A\",     # \"A\" brute-force, \"B\" vector search\n",
    "    do_eval: bool = True,     # run LLM judge + write to rag_evaluations\n",
    "    filters: dict = None,     # optional metadata filters for Vector Search\n",
    "    temperature: float = 0.2\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    End-to-end RAG call:\n",
    "      - Embedding (Azure OpenAI)\n",
    "      - Retrieval (A or B)\n",
    "      - Prompt assembly\n",
    "      - Chat completion (Azure OpenAI)\n",
    "      - Logging (rag_query_logs)\n",
    "      - Optional evaluation (rag_evaluations)\n",
    "\n",
    "    Returns:\n",
    "      {\n",
    "        query_id: str,\n",
    "        question: str,\n",
    "        answer: str,\n",
    "        sources: [...],\n",
    "        eval: {...} | None\n",
    "      }\n",
    "    \"\"\"\n",
    "    if not isinstance(question, str) or not question.strip():\n",
    "        raise ValueError(\"question must be a non-empty string\")\n",
    "\n",
    "    # 1) Embed\n",
    "    q_emb = embed_texts(question)\n",
    "\n",
    "    # 2) Retrieve (returns list[dict])\n",
    "    if retriever.upper() == \"B\":\n",
    "        chunks = retrieve_top_k(q_emb, option=\"B\", k=k, filters=filters)\n",
    "    else:\n",
    "        chunks = retrieve_top_k(q_emb, option=\"A\", k=k)\n",
    "\n",
    "    _validate_chunks(chunks)\n",
    "\n",
    "    # 3) Prompt\n",
    "    prompt = build_prompt(question, chunks)\n",
    "\n",
    "    # 4) Call LLM\n",
    "    resp = aoai.chat.completions.create(\n",
    "        model=CHAT_DEPLOYMENT,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=temperature\n",
    "    )\n",
    "    answer = resp.choices[0].message.content\n",
    "\n",
    "    # 5) Log\n",
    "    rag_event = {\n",
    "        \"question\": question,\n",
    "        \"top_k\": k,\n",
    "        \"retrieved_chunks\": chunks,\n",
    "        \"prompt\": prompt,\n",
    "        \"answer\": answer,\n",
    "        \"embedding_deployment\": EMBEDDING_DEPLOYMENT,\n",
    "        \"chat_deployment\": CHAT_DEPLOYMENT\n",
    "    }\n",
    "    query_id = log_rag_event(rag_event)\n",
    "\n",
    "    # 6) Optional evaluation\n",
    "    eval_result = None\n",
    "    if do_eval:\n",
    "        # judge_rag expects chunk_text to exist; ensure it's present\n",
    "        eval_scores = judge_rag(question, answer, chunks)\n",
    "        eval_id = write_evaluation(\n",
    "            query_id=query_id,\n",
    "            question=question,\n",
    "            answer=answer,\n",
    "            scores=eval_scores,\n",
    "            evaluator=\"llm_judge_v1\"\n",
    "        )\n",
    "        eval_result = {\n",
    "            \"evaluation_id\": eval_id,\n",
    "            **eval_scores\n",
    "        }\n",
    "\n",
    "    return {\n",
    "        \"query_id\": query_id,\n",
    "        \"question\": question,\n",
    "        \"answer\": answer,\n",
    "        \"sources\": _compact_sources(chunks),\n",
    "        \"eval\": eval_result\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c2e17d3f-c157-43f1-a85f-cae6bc73cb03",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/databricks.mlflow.trace": "\"tr-12937a50144345fb9de7aa1f46b2f8f7\"",
      "text/plain": [
       "Trace(request_id=tr-12937a50144345fb9de7aa1f46b2f8f7)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-5573401567029324>, line 4\u001B[0m\n",
       "\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# Notebook “UI” demo cell\u001B[39;00m\n",
       "\u001B[1;32m      3\u001B[0m question \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mHow do I resize an Azure virtual machine?\u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
       "\u001B[0;32m----> 4\u001B[0m result \u001B[38;5;241m=\u001B[39m ask(question, k\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m6\u001B[39m, retriever\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mA\u001B[39m\u001B[38;5;124m\"\u001B[39m, do_eval\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
       "\u001B[1;32m      6\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mQuery ID:\u001B[39m\u001B[38;5;124m\"\u001B[39m, result[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mquery_id\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n",
       "\u001B[1;32m      7\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124mAnswer:\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m, result[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124manswer\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n",
       "\n",
       "File \u001B[0;32m<command-5573401567029257>, line 47\u001B[0m, in \u001B[0;36mask\u001B[0;34m(question, k, retriever, do_eval, filters, temperature)\u001B[0m\n",
       "\u001B[1;32m     44\u001B[0m _validate_chunks(chunks)\n",
       "\u001B[1;32m     46\u001B[0m \u001B[38;5;66;03m# 3) Prompt\u001B[39;00m\n",
       "\u001B[0;32m---> 47\u001B[0m prompt \u001B[38;5;241m=\u001B[39m build_prompt(question, chunks)\n",
       "\u001B[1;32m     49\u001B[0m \u001B[38;5;66;03m# 4) Call LLM\u001B[39;00m\n",
       "\u001B[1;32m     50\u001B[0m resp \u001B[38;5;241m=\u001B[39m aoai\u001B[38;5;241m.\u001B[39mchat\u001B[38;5;241m.\u001B[39mcompletions\u001B[38;5;241m.\u001B[39mcreate(\n",
       "\u001B[1;32m     51\u001B[0m     model\u001B[38;5;241m=\u001B[39mCHAT_DEPLOYMENT,\n",
       "\u001B[1;32m     52\u001B[0m     messages\u001B[38;5;241m=\u001B[39m[{\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrole\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124muser\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcontent\u001B[39m\u001B[38;5;124m\"\u001B[39m: prompt}],\n",
       "\u001B[1;32m     53\u001B[0m     temperature\u001B[38;5;241m=\u001B[39mtemperature\n",
       "\u001B[1;32m     54\u001B[0m )\n",
       "\n",
       "File \u001B[0;32m<command-5573401567029282>, line 4\u001B[0m, in \u001B[0;36mbuild_prompt\u001B[0;34m(question, contexts)\u001B[0m\n",
       "\u001B[1;32m      3\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mbuild_prompt\u001B[39m(question, contexts):\n",
       "\u001B[0;32m----> 4\u001B[0m     joined_context \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mjoin(contexts)\n",
       "\u001B[1;32m      5\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\"\"\u001B[39m\n",
       "\u001B[1;32m      6\u001B[0m \u001B[38;5;124mYou are a helpful assistant answering questions about Azure Compute.\u001B[39m\n",
       "\u001B[1;32m      7\u001B[0m \n",
       "\u001B[0;32m   (...)\u001B[0m\n",
       "\u001B[1;32m     16\u001B[0m \u001B[38;5;124mAnswer:\u001B[39m\n",
       "\u001B[1;32m     17\u001B[0m \u001B[38;5;124m\"\"\"\u001B[39m\n",
       "\n",
       "\u001B[0;31mTypeError\u001B[0m: sequence item 0: expected str instance, dict found"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "datasetInfos": [],
       "jupyterProps": {
        "ename": "TypeError",
        "evalue": "sequence item 0: expected str instance, dict found"
       },
       "metadata": {
        "errorSummary": "<span class='ansi-red-fg'>TypeError</span>: sequence item 0: expected str instance, dict found"
       },
       "removedWidgets": [],
       "sqlProps": null,
       "stackFrames": [
        "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
        "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
        "File \u001B[0;32m<command-5573401567029324>, line 4\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# Notebook “UI” demo cell\u001B[39;00m\n\u001B[1;32m      3\u001B[0m question \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mHow do I resize an Azure virtual machine?\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m----> 4\u001B[0m result \u001B[38;5;241m=\u001B[39m ask(question, k\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m6\u001B[39m, retriever\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mA\u001B[39m\u001B[38;5;124m\"\u001B[39m, do_eval\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m      6\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mQuery ID:\u001B[39m\u001B[38;5;124m\"\u001B[39m, result[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mquery_id\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n\u001B[1;32m      7\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124mAnswer:\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m, result[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124manswer\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n",
        "File \u001B[0;32m<command-5573401567029257>, line 47\u001B[0m, in \u001B[0;36mask\u001B[0;34m(question, k, retriever, do_eval, filters, temperature)\u001B[0m\n\u001B[1;32m     44\u001B[0m _validate_chunks(chunks)\n\u001B[1;32m     46\u001B[0m \u001B[38;5;66;03m# 3) Prompt\u001B[39;00m\n\u001B[0;32m---> 47\u001B[0m prompt \u001B[38;5;241m=\u001B[39m build_prompt(question, chunks)\n\u001B[1;32m     49\u001B[0m \u001B[38;5;66;03m# 4) Call LLM\u001B[39;00m\n\u001B[1;32m     50\u001B[0m resp \u001B[38;5;241m=\u001B[39m aoai\u001B[38;5;241m.\u001B[39mchat\u001B[38;5;241m.\u001B[39mcompletions\u001B[38;5;241m.\u001B[39mcreate(\n\u001B[1;32m     51\u001B[0m     model\u001B[38;5;241m=\u001B[39mCHAT_DEPLOYMENT,\n\u001B[1;32m     52\u001B[0m     messages\u001B[38;5;241m=\u001B[39m[{\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrole\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124muser\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcontent\u001B[39m\u001B[38;5;124m\"\u001B[39m: prompt}],\n\u001B[1;32m     53\u001B[0m     temperature\u001B[38;5;241m=\u001B[39mtemperature\n\u001B[1;32m     54\u001B[0m )\n",
        "File \u001B[0;32m<command-5573401567029282>, line 4\u001B[0m, in \u001B[0;36mbuild_prompt\u001B[0;34m(question, contexts)\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mbuild_prompt\u001B[39m(question, contexts):\n\u001B[0;32m----> 4\u001B[0m     joined_context \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mjoin(contexts)\n\u001B[1;32m      5\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\"\"\u001B[39m\n\u001B[1;32m      6\u001B[0m \u001B[38;5;124mYou are a helpful assistant answering questions about Azure Compute.\u001B[39m\n\u001B[1;32m      7\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     16\u001B[0m \u001B[38;5;124mAnswer:\u001B[39m\n\u001B[1;32m     17\u001B[0m \u001B[38;5;124m\"\"\"\u001B[39m\n",
        "\u001B[0;31mTypeError\u001B[0m: sequence item 0: expected str instance, dict found"
       ],
       "type": "baseError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Notebook “UI” demo cell\n",
    "\n",
    "question = \"How do I resize an Azure virtual machine?\"\n",
    "result = ask(question, k=6, retriever=\"A\", do_eval=True)\n",
    "\n",
    "print(\"Query ID:\", result[\"query_id\"])\n",
    "print(\"\\nAnswer:\\n\", result[\"answer\"])\n",
    "\n",
    "print(\"\\nTop sources:\")\n",
    "for s in result[\"sources\"][:3]:\n",
    "    print(\"-\", s[\"url\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b97e34a2-17f0-4fb6-8eac-40403a5eee78",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Try a few:\n",
    "qs = [\n",
    "    \"What is an availability set used for?\",\n",
    "    \"How do I change VM size in Azure?\",\n",
    "    \"How do I create a VM from an image?\",\n",
    "]\n",
    "for q in qs:\n",
    "    out = ask(q, k=6, retriever=\"A\", do_eval=True)\n",
    "    print(\"\\n======================\")\n",
    "    print(\"Q:\", q)\n",
    "    print(\"A:\", out[\"answer\"][:400], \"...\")\n",
    "    print(\"Faithfulness:\", out[\"eval\"][\"faithfulness\"] if out[\"eval\"] else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4758c24b-3400-4322-b81f-e6644594d480",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Latest logs\n",
    "\n",
    "spark.sql(f\"\"\"\n",
    "SELECT\n",
    "  created_at,\n",
    "  query_id,\n",
    "  question,\n",
    "  top_k,\n",
    "  retrieved_chunks[0].url AS top_source\n",
    "FROM {RAG_LOG_TABLE}\n",
    "ORDER BY created_at DESC\n",
    "LIMIT 20\n",
    "\"\"\").display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b540fa88-a884-4826-b338-0beeccfb0d68",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Latest evaluations\n",
    "\n",
    "spark.sql(f\"\"\"\n",
    "SELECT\n",
    "  created_at,\n",
    "  query_id,\n",
    "  retrieval_relevance,\n",
    "  answer_relevance,\n",
    "  faithfulness,\n",
    "  notes\n",
    "FROM {RAG_EVAL_TABLE}\n",
    "ORDER BY created_at DESC\n",
    "LIMIT 20\n",
    "\"\"\").display()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "07_serving_and_demo",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}